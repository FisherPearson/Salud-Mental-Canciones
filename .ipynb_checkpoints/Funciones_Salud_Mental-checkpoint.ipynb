{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Manejo de Informacion\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\"\"\"Tiempo\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "\n",
    "\"\"\"Textos\"\"\"\n",
    "\n",
    "import re \n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "\n",
    "\"\"\"Visualizaciones\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"ML\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_transform(df):\n",
    "    \"\"\"\n",
    "    Función que transforma de formato CSV a diccionario\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[~(df[\"lyrics\"] == \"error\")] # No tomar en cuenta canciones que no tienen letra\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.str.replace(\"\\r\",\" \").str.replace(\"\\n\",\" \").str.replace(\"[}{&:;,.¡!¿?\\(\\)\\-\\\"\\\"0-9]\",\"\").str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.lower() # Quitar espacios, interlineados, reemplazar algunos signos/numeros y pasar a minúsculas.\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.apply(lambda x: unidecode(x)) # Quitar unicodes de la forma \\uxxxx\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.apply(lambda x: \" \".join(x.split())) # Strippear el texto (quitar espacios innecesarios)\n",
    "    \n",
    "    df[\"tokens\"] = df[\"lyrics\"].apply(lambda x: set(nltk.word_tokenize(x))) # Tokenizar las canciones \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener Datos\n",
    "\n",
    "Se tienen 3 datasets disponibles por si no se quiere/puede obtener la información personal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = CSV_transform(pd.read_csv(\"top_david_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))\n",
    "df2 = CSV_transform(pd.read_csv(\"top_javier_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))\n",
    "#df3 = CSV_transform(pd.read_csv(\"top_jesus_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Obtener_datos(numero):\n",
    "    if numero == 1:\n",
    "        return df1\n",
    "    if numero == 2:\n",
    "        return df2\n",
    "    if numero == 3:\n",
    "        return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier para Identificar idioma\n",
    "\n",
    "En este tópico utilizo:\n",
    "\n",
    "1. __Tema 13: clasificador de Lengua (Naïve Bayes)__\n",
    "2. __Tema 4: Matriz de Incidencia (frecuencias)__\n",
    "\n",
    "Entrenar algorítmo de clasificación para clasificar entre 17 lenguas. Se utilizará el algorítmo visto en clase, pero implementado por Sklearn.\n",
    "\n",
    "[El conjunto de datos etiquetado](https://www.kaggle.com/datasets/basilb2s/language-detection) fue extraido de Kaggle para facilitar el etiquetado. \n",
    "\n",
    "1) English\n",
    "2) Malayalam\n",
    "3) Hindi\n",
    "4) Tamil\n",
    "5) Kannada\n",
    "6) French\n",
    "7) Spanish\n",
    "8) Portuguese\n",
    "9) Italian\n",
    "10) Russian\n",
    "11) Sweedish\n",
    "12) Dutch\n",
    "13) Arabic\n",
    "14) Turkish\n",
    "15) German\n",
    "16) Danish\n",
    "17) Greek\n",
    "\n",
    "__NOTA__: Dado que la longitud de las canciones no es tan extensa, no se aplicará ningún tipo de stemming. Tampoco considero necesario aplicar la técnica de los bigramas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar Dataset\n",
    "lenguajes = pd.read_csv(\"Language Detection.csv\")\n",
    "\n",
    "# Realizar Matriz de Incidencias\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(lenguajes.Text.str.replace(\"[{}:;,.¡!¿?\\(\\)\\\"\\\"0-9]\",\"\").to_list())\n",
    "\n",
    "# Crear modelo \n",
    "\n",
    "NB = MultinomialNB() # Dejar prior como uniforme\n",
    "NB.fit(X, lenguajes.Language.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identificar_Idioma(df):\n",
    "    X_test  = vectorizer.transform(df.lyrics)\n",
    "    \n",
    "    df[\"Idioma\"] = NB.predict(X_test)\n",
    "    \n",
    "    return \"Exitoso Identificador de Idioma\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar palabras de longitud mayor a..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliminar_menor_len(df,limite):\n",
    "    limpias = []\n",
    "    for i in range(df.shape[0]):\n",
    "        limpias.append({palabra_menos for palabra_menos in df.tokens[i] if len(palabra_menos) < limite})\n",
    "    \n",
    "    df[\"tokens\"] = limpias\n",
    "    \n",
    "    return f\"Exitosa eliminación de palabras con longitud mayor a {limite}\"\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stopwords(df):\n",
    "    # Lista de idiomas\n",
    "    idiomas = df.Idioma.unique()\n",
    "    \n",
    "    \n",
    "    for idioma in idiomas:\n",
    "        try:\n",
    "            stopwords_ = stopwords.words(idioma) # Stopwords\n",
    "        except:\n",
    "            print(\"No hay stopwords para\", idioma)\n",
    "            \n",
    "        canciones_idioma = df[df[\"Idioma\"] == idioma][\"tokens\"]\n",
    "        \n",
    "        for indice in canciones_idioma.index:\n",
    "            canciones_idioma[indice] = [palabra for palabra in canciones_idioma[indice] if palabra not in stopwords_]\n",
    "            \n",
    "        test.iloc[canciones_idioma.index,2] = canciones_idioma\n",
    "        \n",
    "    return \"Exitosa eliminación de stopwords por idioma\"\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frecuencia de términos por idioma\n",
    "\n",
    "En este tópico utilizo:\n",
    "\n",
    "1. __Tema 2: Estadísticas Corpus__\n",
    "\n",
    "Abrir un intervalo centrado en la palabra de interés para encontrar contexto, así como en la canción que fue encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x000001CBC7884220>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"Idioma\"])[\"tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Obtener_datos(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exitoso Identificador de Idioma'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Identificar_Idioma(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exitosa eliminación de palabras con longitud mayor a 10'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eliminar_menor_len(test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exitosa eliminación de stopwords por idioma'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stopwords(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pieles', 'entiendo', 'magia', 'puro', 'redes', 'truquito', 'cinturita', 'demonios', 'fuego', 'todavia', 'da', 'noche', 'manicomio', 'si', 'acelerara', 'foto', 'pa', 'encanta', 'mami', 'manzana', 'baby', 'combo', 'insomnio', 'llevame', 'quiere', 'clara', \"'\", 'frenara', 'quiero', 'cambia', 'veneno', 'dicen', 'mujeres', 'sube', 'ganas', 'calara', 'manzanita', 'pura', 'evidente', 'acerco', 'ojos', 'conocer', 'yeahyeah', 'cometido', 'solo', 'emprende', 'lady', 'biri', 'deseo', 'babylon', 'crimen', 'amanecer', 'oh', 'halagado', 'explico', 'tenerte', 'despues', 'dame', 'acercate', 'iba', 'haber', 'peor', 'pasado', 'terminar', 'dejaria', 'uh', 'girl', 'asi', 'haberte', 'primer', 'aqui', 'besado', 'poquito', 'uuh', 'entiende', 'ere', 'desarmado', 'chama', 'vi', 'cama', 'suena', 'momentico', 'momento', 'boquita', 'corazon', 'cuarto', 'bababa', 'apague', 'yeheh', 'hacerte', 'huele', 'dice', 'dispuesta', 'mejor', 'fiel', 'manana', 'pensarte', 'dior', 'ocupado', 'ves', 'bonita', 'cosas', 'nube', 'merece', 'sol', 'entender', 'piel', 'conmigo', 'babababy', 'llorar', 'bebe', 'ver', 'carro', 'christian', 'propuesta', 'deja', 'tres', 'respuesta', 'dos', 'va', 'mas', 'maluma', 'tampoco', 'dejes', 'contesta', 'brillante', 'once', 'lanzame', 'reina', 'olerte', 'hazlo', 'hombre', 'nuevo', 'matame', 've', 'bien', 'echa', 'ohoh', 'decir', 'dime', 'voz', 'alguna', 'cuantas', 'cada', 'decente', 'demasiado', 'derrito', 'ey', 'serte', 'queda', 'arrugo', 'hechizas', 'vez', 'batete', 'cae', 'paso', 'querer', 'escucha', 'ajedrez', 'chin', 'veces', 'verte', 'eyey', \"'cercate\", 'gente', 'pasarte', 'detenerte', 'swing', 'pelo', 'enrede', 'lado', 'ay', 'gana', 'ir', 'esperarte', 'remix', 'show', 'music', 'motivo', 'flow', 'van', 'adicto', 'eh', 'dejo', 'oye', 'treparte', 'rich', 'all', \"calla'ita\", 'activa', 'gaby', 'sigo', 'chencho', 'dia', 'darte', 'conociste', 'apaga', 'haria', 'quitar', 'grosero', 'besaaaaar', 'vuelve', 'falda', 'siempre', 'sou', 'enredaria', 'llego', 'amiga', 'mueves', 'yeih', 'pruebo', 'ven', 'panticito', 'dimelo', 'arrebata', 'this', 'repetimos', 'cuerpo', 'star', 'cuenta', 'sero', 'puede', 'puras', 'rica', 'morales', 'dembow', 'pago', 'atreve', 'bellaqueo', 'dalex', 'is', 'juhn', 'tire', 'to', 'okay', 'hola', 'admirante', 'corleone', 'yah', 'acuerdas', 'so', 'quihubo', 'the', 'waowwaow', 'saber', 'ahi', 'loco', 'baila', 'pieeeeel', 'ojo', 'acelero', 'ohuoh', 'magnifico', 'buena', 'erice', 'hace', 'prendi', 'jukia', 'wuh', 'jajaja', 'confia', 'tiempo', 'ah', 'pediras', 'ba', 'hablaba', 'contaba', 'quitaria', 'subirte', 'suceria', 'vas', 'boca', 'ropa', 'sere', 'nena', 'uhyeh', 'bailas', 'chica', 'jeje', 'cero', 'maaaaas', 'igual', 'nunca', 'decia', 'hare', 'vuelva', 'capte', 'pared', 'tan', 'espero', 'fanatico', 'ma', 'veo', 'quede', 'ohwoh', 'veia', 'ponerte', 'suspende', 'contigo', 'tigo', 'pasion', 'siento', 'estela', 'verdad', 'verdda', 'bendicion', 'gusta', 'estrella', 'puedo', 'mistica', 'miro', 'gustas', 'companar', 'digo', 'tedigo', 'fugas', 'miras', 'lastimar', 'timar', 'viivo', 'entoxica', 'novio', 'felice', 'nonono', 'hoy', 'importa', 'soltera', 'here', 'wohwohwoh', 'seguro', 'cicatrice', 'busco', 'musica', 'escribir', 'ritmo', \"'tas\", 'mercede', 'ahora', 'oscuro', 'llama', 'reclama', 'muerte', 'felicidad', 'calle', 'that', 'perder', 'tomandose', 'woh', 'again', 'abajo', 'duro', 'saludo', 'despoja', 'fuma', 'place', 'tetri', 'llega', 'rondon', 'nadie', 'dias', 'complace', 'yehyehyeh', 'monte', 'cuadrito', 'jode', 'borrachar', 'batidora', 'eeeeees', 'dije', \"'ta\", 'sudando', 'diga', 'go', 'peti', 'amando', 'anuel', 'noohoh', 'pasando', 'llora', 'visto', 'nigga', 'pone', 'clave', 'juro', 'suene', 'real', 'dificil', 'tambien', 'pon', 'casa', 'vamo', 'sabe', 'ultima', 'gang', 'ama', 'sido', 'creo', 'beso', 'gris', 'acabe', 'nota', 'pena', 'petite', 'sola', 'demasia', 'uah', 'amor', 'grise', 'vida', 'uahahah', 'botella', 'rompe', 'fumar', 'disfruta', 'dale', 'sigue', 'borracha', 'pille', \"'tes\", 'curo', 'facil', 'cabe', 'voy', 'mio', 'stop', 'ca', 'toda', 'toma', '*', 'ahah', 'tranquila', 'mientra', 'pidiendo', 'haga', 'siendo', 'amigos', 'dijo', 'censura', 'roja', 'olvidando', 'perreo', 'hazle', 'acabando', 'hah', 'maleti', 'olvido', 'resalta', 'tra-', 'rompemo', 'negro', 'sale', 'disimulo', 'ice', 'we', 'yeah', 'ahahah', 'meto', 'discotek', 'malo', 'dejaron', 'dj', 'par', 'parar', 'rudo', 'hora', 'shit', 'everybody', 'bajo', 'cambio', 'beber', 'perdoname', 'atention', 'pierde', 'ratatata', 'mire', 'hablar', 'bailar', 'moja', 'enamora', 'sonroja', 'linda', 'coja', 'valora', 'alta', 'quiso', 'lambo', 'sepa', 'na', 'pide', 'verda', 'segundo', 'decirte', 'niegues', 'perdi', 'mirada', 'amarnos', 'aun', 'amarte', 'palabras', 'pense', 'pasa', 'mirame', 'mente', 'urges', 'mundo', 'amado', 'extrano', 'locos', 'encontre', 'poder', 'tener', 'modo', 'sabes', 'tocarte', 'necesito', 'perfecto', 'dentro', 'apoderan', 'pienso', 'enloqueci', 'pedi', 'oido', 'rebelde', 'fuerte', 'amigas', 'quedate', 'lalo', 'lista', 'cafe', 'invitarte', 'sonriente', 'primera', 'llevaba', 'cara', 'llegue', 'pretexto', 'quieres', 'volvamos', 'dios', 'primero', 'hacia', 'junto', 'carita', 'rola', 'volvere', 'acerque', 'atrevi', 'bar', 'atardecer', 'rico', 'quizas', 'pensar', 'ultimo', 'presente', 'camino', 'instinto', 'suele', 'quiza', 'vienes', 'sonrisa', 'pegaditos', 'mananas', 'gozar', 'mirar', 'vista', 'duermas', 'vengas', 'vayas', 'volverte', 'incitaba', 'queria', 'besos', 'suceder', 'favor', 'angel', 'tequila', 'volver', 'destino', 'rubi', 'segui', 'internet', 'sonaba', 'ojala', 'pasar', 'tomar', 'comenzar', 'ready', 'rima', 'punchline', 'codeina', 'mira', 'dile', 'bebecita', 'mitad', 'mismo', 'recibo', 'saliste', 'pregunto', 'dieta', 'encima', 'blunt', 'cocina', 'adictiva', 'neta', 'fresh', 'what', 'conoci', 'separara', 'busque', 'papi', 'niagara', 'perra', 'pacino', 'tv', 'dura', 'chulita', 'vamos', 'little', 'parcera', 'miss', 'rudeboyz', 'wayne', 'amen', 'encuentro', 'completa', 'discreta', 'jordan', 'i', 'vino', 'bastaron', 'mamacita', 'aunque', 'babe', 'up', 'medallo', 'fanatica', 'camina', 'bicicleta', 'comi', 'echarle', 'famosa', 'know', 'perdon', 'hiciste', 'copas', 'you', 'juancho', 'suspiros', 'vinci', 'delfin', 'poetas', 'dibujo', 'mar', 'aliento', 'acuarela', 'circo', 'undo', 'arcoiris', 'fin', 'musa', 'mejilla', 'carmin', 'gogh', 'cruzo', 'nado', 'harmonia', 'sentir', 'inundo', 'yola', 'profundas', 'hecha', 'alumbra', 'brutal', 'pido', 'fantasias', 'desnudo', 'flores', 'menguante', 'mancha', 'emociones', 'dormir', 'deslumbra', 'jardin', 'esplendor', 'cancion', 'increible', 'rodillas', 'magueyes', 'historia', 'lluvia', 'cielo', 'subiremos', 'culpa', 'pondre', 'bajaremos', 'alma', 'olvides', 'veladoras', 'jaulas', 'condenar', 'nombre', 'paredes', 'altar', 'restos', 'andaremos', 'olviden', 'fuga', 'cuidare', 'haremos', 'belleza', 'pese', 'yahyah', 'sonado', 'planes', 'cambiaron', 'caminen', 'unico', 'diria', 'milesimas', 'under', 'piernas', 'ano', 'persigo', 'ido', 'amarraron', 'valen', 'memoria', 'perro', 'falle', 'parches', 'prometido', 'pase', 'jajajaja', 'ducha', 'tanta', 'creia', 'pintura', 'desnudita', 'justo', 'olvide', 'exquisita', 'menos', 'robaron', 'horas', 'necesario', 'pesen', 'wohohohoh', 'mia', 'hicimos', 'estire', 'hechos', 'perderte', 'mojaita', 'anos', 'vuelven', 'quita', 'fina', 'explica', 'salimos', 'queden', 'cierren', 'wohoh', 'solas', 'sabor', 'senti', 'llevas', 'llamada', 'robarte', 'extranas', 'dueno', 'noches', 'boy', 'pretty', 'genio', 'chan', 'llevan', 'intimidad', 'probare', 'decias', 'kevin', 'dudes', 'melodia', 'durara', 'mujer', 'luz', 'indio', 'tenue', 'enganes', 'miel', 'mata', 'conoce', 'formula', 'msima', 'caliento', 'gritabas', 'frias', 'digas', 'paraliza', 'alegra', 'secreto', 'labios', 'descubrir', 'calor', 'sientas', 'ta', 'preguntas', 'media', 'siguiente', 'aquellos', 'quisiera', 'pues', 'prestas', 'recibir', 'extasis', 'its', 'sombras', 'pedir', 'adj', 'dulce', 'llevo', 'falta', 'cabo'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(list(chain(*test[test[\"Idioma\"] == \"Spanish\"][\"tokens\"].to_list()))).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
