{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Manejo de Informacion\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\"\"\"Tiempo\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "\n",
    "\"\"\"Textos\"\"\"\n",
    "\n",
    "import re \n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\"\"\"Visualizaciones\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"ML\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_transform(df):\n",
    "    \"\"\"\n",
    "    Función que transforma de formato CSV a diccionario\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[~(df[\"lyrics\"] == \"error\")] # No tomar en cuenta canciones que no tienen letra\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.str.replace(\"\\r\",\" \").str.replace(\"\\n\",\" \").str.replace(\"[}{&:;,.¡!¿?\\(\\)\\-\\\"\\\"0-9]\",\"\").str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.lower() # Quitar espacios, interlineados, reemplazar algunos signos/numeros y pasar a minúsculas.\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.apply(lambda x: unidecode(x)) # Quitar unicodes de la forma \\uxxxx\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.apply(lambda x: \" \".join(x.split())) # Strippear el texto (quitar espacios innecesarios)\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener Datos\n",
    "\n",
    "Se tienen 3 datasets disponibles por si no se quiere/puede obtener la información personal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = CSV_transform(pd.read_csv(\"top_david_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))\n",
    "df2 = CSV_transform(pd.read_csv(\"top_javier_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))\n",
    "df3 = CSV_transform(pd.read_csv(\"top_jesus_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Obtener_datos(numero):\n",
    "    if numero == 1:\n",
    "        return df1\n",
    "    if numero == 2:\n",
    "        return df2\n",
    "    if numero == 3:\n",
    "        return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier para Identificar idioma\n",
    "\n",
    "En este tópico utilizo:\n",
    "\n",
    "1. __Tema 13: clasificador de Lengua (Naïve Bayes)__\n",
    "2. __Tema 4: Matriz de Incidencia (frecuencias)__\n",
    "\n",
    "Entrenar algorítmo de clasificación para clasificar entre 17 lenguas. Se utilizará el algorítmo visto en clase, pero implementado por Sklearn.\n",
    "\n",
    "[El conjunto de datos etiquetado](https://www.kaggle.com/datasets/basilb2s/language-detection) fue extraido de Kaggle para facilitar el etiquetado. \n",
    "\n",
    "1) English\n",
    "2) Malayalam\n",
    "3) Hindi\n",
    "4) Tamil\n",
    "5) Kannada\n",
    "6) French\n",
    "7) Spanish\n",
    "8) Portuguese\n",
    "9) Italian\n",
    "10) Russian\n",
    "11) Sweedish\n",
    "12) Dutch\n",
    "13) Arabic\n",
    "14) Turkish\n",
    "15) German\n",
    "16) Danish\n",
    "17) Greek\n",
    "\n",
    "__NOTA__: Dado que la longitud de las canciones no es tan extensa, no se aplicará ningún tipo de stemming. Tampoco considero necesario aplicar la técnica de los bigramas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar Dataset\n",
    "lenguajes = pd.read_csv(\"Language Detection.csv\")\n",
    "\n",
    "# Realizar Matriz de Incidencias\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(lenguajes.Text.str.replace(\"[{}:;,.¡!¿?\\(\\)\\\"\\\"0-9]\",\"\").to_list())\n",
    "\n",
    "# Crear modelo \n",
    "\n",
    "NB = MultinomialNB() # Dejar prior como uniforme\n",
    "NB.fit(X, lenguajes.Language.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identificar_Idioma(df):\n",
    "    X_test  = vectorizer.transform(df.lyrics)\n",
    "    \n",
    "    df[\"Idioma\"] = NB.predict(X_test)\n",
    "    \n",
    "    return \"Exitoso Identificador de Idioma\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completado de palabras en español en caso de contracción\n",
    "\n",
    "En este tópico utilizo:\n",
    "\n",
    "1. __Tema 6: Levenshtein Metric__\n",
    "\n",
    "En español, como bien sabemos, no existen formalmente; sin embargo, pragmáticamente se ha adquirido la costumbre de \"recortar\" algunas palabras y la forma de representar este fenómeno es por medio de un __'__. Comunmente estas contracciones se efectuan __en preposiciones__, esto es, stopwords. En cuanto a RI no son relevantes, pero para la interpretación literaria del texto, sí.\n",
    "\n",
    "Se pretende identificar estas palabras y completarlas por medio de una lista de palabras comunmente contraidas (informalmente) en el español. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Contracciones_español(df,porcentaje = 60, lista_extra = []): \n",
    "    assert \"Spanish\" in df[\"Idioma\"].unique(), 'No escuchas música en español'\n",
    "    \n",
    "    lista = lista_extra + [palabra for palabra in stopwords.words(\"Spanish\") if len(palabra) >=3]\n",
    "    \n",
    "    español = df[df[\"Idioma\"] == \"Spanish\"][\"lyrics\"]\n",
    "    \n",
    "    for indice in español.index:\n",
    "            palabras_cancion = español[indice].split()\n",
    "            \n",
    "            for index in range(len(palabras_cancion)):\n",
    "                if \"'\" in palabras_cancion[index]:\n",
    "                    try:\n",
    "                        palabras_cancion[index] =  process.extractOne(palabras_cancion[index], lista,score_cutoff = porcentaje)[0]\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            cancion_corregida = \" \".join(palabras_cancion)\n",
    "            \n",
    "            df.iloc[indice,1] = cancion_corregida\n",
    "    \n",
    "    return \"Exitosa corrección de palabras en la lista\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contracciones (')\n",
    "\n",
    "En este tópico utilizo:\n",
    "\n",
    "1. __Tema 3: Regex (Expresiones regulares)__\n",
    "\n",
    "Dado que en algunas lenguas romances el uso de __'__ resulta determinante para el contexto de la oración, no puede ser fácilmente eliminado del corpus. En adición, las contracciones en el idioma inglés también existen y son muy comunes.  En general, en caso de que la contracción sea entre una preposición y una palabra relevante, es más probable que la palabra sea de mediana longitud. La función está primordialmente orientada a lenguas romance (incluyendo inglés) que las utilicen.\n",
    "\n",
    "Se pretende identificar contracciones útiles por medio de la identificación de la longitud de la segunda palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizar Canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenizar(df):\n",
    "    df[\"tokens\"] = df[\"lyrics\"].apply(lambda x: set(nltk.word_tokenize(x))) # Tokenizar las canciones\n",
    "    \n",
    "    return \"Exitoso Tokenizado\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar palabras de longitud mayor a..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliminar_mayor_len(df,limite):\n",
    "    limpias = []\n",
    "    for i in range(df.shape[0]):\n",
    "        limpias.append({palabra_menos for palabra_menos in df.tokens[i] if len(palabra_menos) < limite})\n",
    "    \n",
    "    df[\"tokens\"] = limpias\n",
    "    \n",
    "    return f\"Exitosa eliminación de palabras con longitud mayor a {limite}\"\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar palabras de longitud menor a..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliminar_menor_len(df,limite):\n",
    "    limpias = []\n",
    "    for i in range(df.shape[0]):\n",
    "        limpias.append({palabra_menos for palabra_menos in df.tokens[i] if len(palabra_menos) > limite})\n",
    "    \n",
    "    df[\"tokens\"] = limpias\n",
    "    \n",
    "    return f\"Exitosa eliminación de palabras con longitud menor a {limite}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stopwords(df):\n",
    "    # Lista de idiomas\n",
    "    idiomas = df.Idioma.unique()\n",
    "    \n",
    "    \n",
    "    for idioma in idiomas:\n",
    "        try:\n",
    "            stopwords_ = stopwords.words(idioma) # Stopwords\n",
    "        except:\n",
    "            print(\"No hay stopwords para\", idioma)\n",
    "            \n",
    "        canciones_idioma = df[df[\"Idioma\"] == idioma][\"tokens\"]\n",
    "        \n",
    "        for indice in canciones_idioma.index:\n",
    "            canciones_idioma[indice] = [palabra for palabra in canciones_idioma[indice] if palabra not in stopwords_]\n",
    "            \n",
    "        test.iloc[canciones_idioma.index,2] = canciones_idioma\n",
    "        \n",
    "    return \"Exitosa eliminación de stopwords por idiomas identificados\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Obtener_datos(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exitoso Identificador de Idioma'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Identificar_Idioma(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exitosa corrección de palabras en la lista'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contracciones_español(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contracciones(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizar(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eliminar_mayor_len(test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eliminar_menor_len(test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [palabra for palabra in FreqDist(list(chain(*test[\"tokens\"].to_list()))).keys() if \"'\" in palabra]: #[test[\"Idioma\"] == \"English\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
