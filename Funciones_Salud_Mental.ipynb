{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Manejo de Informacion\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\"\"\"Tiempo\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "\n",
    "\"\"\"Textos\"\"\"\n",
    "\n",
    "import re \n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\"\"\"Visualizaciones\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"ML\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_transform(df):\n",
    "    \"\"\"\n",
    "    Función que transforma de formato CSV a diccionario\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[~(df[\"lyrics\"] == \"error\")] # No tomar en cuenta canciones que no tienen letra\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.str.replace(\"\\r\",\" \").str.replace(\"\\n\",\" \").str.replace(\"[:;,.¡!¿?\\(\\)\\-\\\"\\\"0-9]\",\"\").str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.lower() # Quitar espacios, interlineados, reemplazar algunos signos/numeros y pasar a minúsculas.\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.apply(lambda x: unidecode(x)) # Quitar unicodes de la forma \\uxxxx\n",
    "    \n",
    "    df[\"lyrics\"] = df.lyrics.apply(lambda x: \" \".join(x.split())) # Strippear el texto (quitar espacios innecesarios)\n",
    "    \n",
    "    df[\"tokens\"] = df[\"lyrics\"].apply(lambda x: set(nltk.word_tokenize(x))) # Tokenizar las canciones \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = CSV_transform(pd.read_csv(\"top_david_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))\n",
    "df2 = CSV_transform(pd.read_csv(\"top_javier_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))\n",
    "#df3 = CSV_transform(pd.read_csv(\"top_jesus_spotify.csv\",usecols = [\"name\",\"lyrics\"]).dropna().reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Obtener_datos(numero):\n",
    "    if numero == 1:\n",
    "        return df1\n",
    "    if numero == 2:\n",
    "        return df2\n",
    "    if numero == 3:\n",
    "        return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier para encontrar idioma\n",
    "\n",
    "En este tópico utilizo:\n",
    "\n",
    "1. __Tema 13: clasificador de Lengua (Naïve Bayes)__\n",
    "2. __Tema 4: Matriz de Incidencia (frecuencias)__\n",
    "\n",
    "Entrenar algorítmo de clasificación para clasificar entre 4 lenguas: Español, Inglés, Francés y Portugués. Se utilizará el algorítmo visto en clase, pero implementado por Sklearn.\n",
    "\n",
    "[El conjunto de datos etiquetado](https://www.kaggle.com/datasets/basilb2s/language-detection) fue extraido de Kaggle para facilitar el etiquetado. \n",
    "\n",
    "1) English\n",
    "2) Malayalam\n",
    "3) Hindi\n",
    "4) Tamil\n",
    "5) Kannada\n",
    "6) French\n",
    "7) Spanish\n",
    "8) Portuguese\n",
    "9) Italian\n",
    "10) Russian\n",
    "11) Sweedish\n",
    "12) Dutch\n",
    "13) Arabic\n",
    "14) Turkish\n",
    "15) German\n",
    "16) Danish\n",
    "17) Greek\n",
    "\n",
    "__NOTA__: Dado que la longitud de las canciones no es tan extensa, no se aplicará ningún tipo de stemming. Tampoco considero necesario aplicar la técnica de los bigramas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar Dataset\n",
    "lenguajes = pd.read_csv(\"Language Detection.csv\")\n",
    "\n",
    "# Realizar Matriz de Incidencias\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(lenguajes.Text.str.replace(\"[:;,.¡!¿?\\(\\)\\\"\\\"0-9]\",\"\").to_list())\n",
    "\n",
    "# Crear modelo \n",
    "\n",
    "NB = MultinomialNB() # Dejar prior como uniforme\n",
    "NB.fit(X, lenguajes.Language.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identificar_Idioma(df):\n",
    "    X_test  = vectorizer.transform(df.lyrics)\n",
    "    \n",
    "    df[\"Idioma\"] = NB.predict(X_test)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV_transform(df2).lyrics[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#songs[\"tokens\"] = songs[\"lyrics\"].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1 = df1[~(df1[\"lyrics\"] == \"error\")]\n",
    "\n",
    "df1[\"lyrics\"] = df1.lyrics.str.replace(\"\\r\",\" \").str.replace(\"\\n\",\" \").str.replace(\"[:;,.¡!¿?\\(\\)\\-\\\"\\\"]\",\"\").str.lower()\n",
    "\n",
    "\n",
    "df1[\"lyrics\"] = df1.lyrics.apply(lambda x: unidecode(x))\n",
    "\n",
    "df1[\"lyrics\"] = df1.lyrics.apply(lambda x: \" \".join(x.split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
